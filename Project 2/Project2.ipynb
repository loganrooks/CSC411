{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project2.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"2UBA0cNIwdMt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":4}],"base_uri":"https://localhost:8080/","height":119},"outputId":"2407eb2b-39eb-4d3a-deb2-101f9788f8a2","executionInfo":{"status":"ok","timestamp":1518974503231,"user_tz":300,"elapsed":1376,"user":{"displayName":"Logan Rooks","photoUrl":"//lh6.googleusercontent.com/-qETJT5Z1tdA/AAAAAAAAAAI/AAAAAAAAAVA/F5NHtBKc70Q/s50-c-k-no/photo.jpg","userId":"112096945625327662556"}}},"cell_type":"code","source":["!git clone https://github.com/loganrooks/CSC411.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'CSC411'...\n","remote: Counting objects: 1810, done.\u001b[K\n","remote: Compressing objects: 100% (896/896), done.\u001b[K\n","remote: Total 1810 (delta 900), reused 1794 (delta 899), pack-reused 15\u001b[K\n","Receiving objects: 100% (1810/1810), 15.85 MiB | 45.32 MiB/s, done.\n","Resolving deltas: 100% (901/901), done.\n"],"name":"stdout"}]},{"metadata":{"id":"Kd2GDJFmjE28","colab_type":"text"},"cell_type":"markdown","source":["## Part 0: Preparing Data"]},{"metadata":{"id":"FXniDz0YHs4o","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.cbook as cbook\n","import time\n","\n","from scipy.io import loadmat\n","from scipy.misc import imread\n","from scipy.misc import imresize\n","from scipy.ndimage import filters\n","import matplotlib.image as mpimg\n","\n","import urllib\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"APBf6PsrIx2i","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.datasets import fetch_mldata\n","mnist = fetch_mldata('MNIST original')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L_VhOfQGKBb3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"e9b8f1d2-d365-4ecb-a99c-e60723495e39","executionInfo":{"status":"ok","timestamp":1518901093703,"user_tz":300,"elapsed":704,"user":{"displayName":"Logan Rooks","photoUrl":"//lh6.googleusercontent.com/-qETJT5Z1tdA/AAAAAAAAAAI/AAAAAAAAAVA/F5NHtBKc70Q/s50-c-k-no/photo.jpg","userId":"112096945625327662556"}}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X, X_test, y, y_test = train_test_split(mnist[\"data\"], mnist[\"target\"], train_size=0.8, random_state=411)\n","X, y, X_test, y_test = X/255.0, y, X_test/255.0, y_test\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=411)\n","print X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(44800, 784) (44800,) (11200, 784) (11200,) (14000, 784) (14000,)\n"],"name":"stdout"}]},{"metadata":{"id":"0iMQ6gZ2kn_H","colab_type":"text"},"cell_type":"markdown","source":["## Part 1: Visualizing the Dataset"]},{"metadata":{"id":"ZSYKyzi3MkeO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":254},"outputId":"6785e2c0-6d50-4024-a0b5-68215a2debb6","executionInfo":{"status":"ok","timestamp":1518849298159,"user_tz":300,"elapsed":2484,"user":{"displayName":"Logan Rooks","photoUrl":"//lh6.googleusercontent.com/-qETJT5Z1tdA/AAAAAAAAAAI/AAAAAAAAAVA/F5NHtBKc70Q/s50-c-k-no/photo.jpg","userId":"112096945625327662556"}}},"cell_type":"code","source":["n_samples = 5\n","n_classes = 10\n","for number in range(n_classes):\n","  samples = X_train[y_train==number][:n_samples]\n","  for sample_idx in range(n_samples):\n","    index = number + sample_idx * n_classes + 1\n","    fig = plt.subplot(n_samples,n_classes, index)\n","    fig.axes.get_xaxis().set_visible(False)\n","    fig.axes.get_yaxis().set_visible(False)\n","    plt.imshow(samples[sample_idx].reshape(28,28))\n","    if sample_idx == 0: \n","      plt.title(\"{}\".format(number))"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAV0AAADtCAYAAAAcNaZ2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAdT9Ab2LHYAEAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7f28cd37eed0>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"702TlNaqMnZ_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def one_hot_encode(labels):\n","  n_out = np.unique(labels).shape[0]\n","  encoding = np.eye(n_out)\n","  y = np.array([encoding[int(label)] for label in labels]).reshape(-1, n_out)\n","  return y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m94qI7LRSp09","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":102},"outputId":"9cd90084-872d-443b-9fa6-8c37df09e74e","executionInfo":{"status":"ok","timestamp":1518849584559,"user_tz":300,"elapsed":282,"user":{"displayName":"Logan Rooks","photoUrl":"//lh6.googleusercontent.com/-qETJT5Z1tdA/AAAAAAAAAAI/AAAAAAAAAVA/F5NHtBKc70Q/s50-c-k-no/photo.jpg","userId":"112096945625327662556"}}},"cell_type":"code","source":["y_train_one_hot = one_hot_encode(y_train)\n","y_valid_one_hot = one_hot_encode(y_valid)\n","print y_train_one_hot[:5]"],"execution_count":33,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"gkMCPKXc60BK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def softmax(x):\n","  exp = np.exp(x)\n","  return exp / exp.sum()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WkAsgPQ8TwKU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class cross_entropy():\n","  def __init__(self, model, weight_decay=0.0001):\n","    self.model = model\n","    self.weight_decay = weight_decay\n","    \n","  def gradients(self, X, y_pred, y):\n","    n_samples = y.shape[0]\n","    # print(X.shape)\n","    # print(self.model.weights.shape)\n","    w_gradients = (1.0/n_samples) * np.matmul((y_pred - y).T, X) + self.weight_decay * self.model.weights\n","    b_gradients = np.sum(y_pred - y, axis=0).reshape(-1,1)/n_samples\n","    return w_gradients, b_gradients\n","  \n","  def calculate(self, y_pred, y):\n","    n_samples = y.shape[0]\n","    return -np.sum(y * np.log(y_pred))/n_samples + (0.5)*self.weight_decay*np.sum(np.matmul(self.model.weights.T, self.model.weights))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QscfElzIyYh9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class OneLayerNetwork():\n","  def __init__(self, n_inputs, n_outputs, weights=None, biases=None):\n","    # Initialize weights with predefined weights or use He Initialization\n","    self.weights = weights if weights != None else np.random.randn(n_outputs, n_inputs) / np.sqrt(n_inputs)\n","    # Initialize biases with zeroes since symmetry breaking has already been done \n","    self.biases = biases if biases != None else np.zeros((n_outputs, 1))\n","    self.epochs = 0                                          \n","    \n","  def forward(self, X):\n","    logits = np.matmul(X, self.weights.T) + self.biases.T\n","    y_pred = softmax(logits)                                                     \n","    return y_pred\n","  \n","  def train(self, X_train, y_train, X_valid, y_valid, init_alpha=0.1, weight_decay=0.0001, batch_size=32, n_epochs=10, steps_until_eval=100, loss=cross_entropy):\n","    n_samples = X_train.shape[0]\n","    self.loss = loss(self, weight_decay)\n","    alpha = init_alpha\n","    best_loss = np.infty\n","    evals_since_last_best = 0\n","    for epoch in range(n_epochs):\n","      step = 0                                                   \n","      batch_indices = np.random.permutation(range(n_samples)).reshape(-1,batch_size)\n","      X_batches = tuple(X_train[batch_indices, :]) \n","      y_batches = tuple(y_train[batch_indices, :])  \n","      # print batches\n","      for batch in zip(X_batches, y_batches):\n","        X_batch = batch[0]\n","        y_batch = batch[1]\n","        # print batch[0].shape\n","        # print batch[1].shape\n","        y_pred = self.forward(X_batch)\n","        gradients = self.loss.gradients(X_batch, y_pred, y_batch)\n","        # print gradients[1].shape\n","        self.weights -= alpha*gradients[0]\n","        self.biases -= alpha*gradients[1]\n","        step += 1\n","        \n","        if step % 100 == 0:\n","          print \"Epoch: {}, Step: {} \\n\".format(epoch, step)\n","          train_accuracy, train_loss = self.evaluation(y_pred, y_batch, self.loss)\n","          print \"Training Set: Accuracy: {}, Loss: {} \\n\".format(train_accuracy, train_loss)\n","          y_pred_valid = self.forward(X_valid)\n","          valid_accuracy, valid_loss = self.evaluation(y_pred_valid, y_valid, self.loss)\n","          print \"Validation Set: Accuracy: {}, Loss: {} \\n\".format(valid_accuracy, valid_loss)\n","          \n","          if valid_loss < best_loss:\n","            evals_since_last_best = 0\n","            best_loss = valid_loss\n","            best_accuracy = valid_accuracy\n","            best_params = [self.weights, self.biases]\n","          else:\n","            evals_since_last_best += 1\n","            \n","          if evals_since_last_best > 4:\n","            alpha /= 10     \n","            \n","          print \"Best Accuracy: {}, Best Loss: {} \\n\\n\".format(best_accuracy, best_loss)\n","      for category in range(self.weights.shape[0]):\n","        plt.imsave(\"weights_c{}_t{}_v{}_e{}.jpg\".format(category, train_accuracy, valid_accuracy, epoch), self.weights[category, :].reshape(28,28))        \n","    self.weights = best_params[0]\n","    self.biases = best_params[1]\n","          \n","                                                                                                                 \n","  def evaluation(self, y_pred, y, loss):\n","    n_samples = y.shape[0]                                                                                                        \n","    n_correct = float(np.equal(np.argmax(y_pred, axis=1), np.argmax(y, axis=1)).sum())\n","    accuracy = n_correct / n_samples\n","    return accuracy, loss.calculate(y_pred, y)                                                                                                                                                    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"i8xo4mHiVmAK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"d6737006-c420-4d8a-ef74-a919b9c3fe95","executionInfo":{"status":"ok","timestamp":1518852075418,"user_tz":300,"elapsed":1310,"user":{"displayName":"Logan Rooks","photoUrl":"//lh6.googleusercontent.com/-qETJT5Z1tdA/AAAAAAAAAAI/AAAAAAAAAVA/F5NHtBKc70Q/s50-c-k-no/photo.jpg","userId":"112096945625327662556"}}},"cell_type":"code","source":["n_inputs = X_train.shape[1]\n","n_outputs = y_train_one_hot.shape[1]\n","print n_inputs, n_outputs"],"execution_count":230,"outputs":[{"output_type":"stream","text":["784 10\n"],"name":"stdout"}]},{"metadata":{"id":"-PwFTvyQfMsn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["net = OneLayerNetwork(n_inputs, n_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B2pHso--fhFd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":7},{"item_id":18},{"item_id":26}],"base_uri":"https://localhost:8080/","height":21437},"outputId":"cd896511-a3f3-4705-f92b-dd34ff47f26f","executionInfo":{"status":"ok","timestamp":1518852089590,"user_tz":300,"elapsed":11961,"user":{"displayName":"Logan Rooks","photoUrl":"//lh6.googleusercontent.com/-qETJT5Z1tdA/AAAAAAAAAAI/AAAAAAAAAVA/F5NHtBKc70Q/s50-c-k-no/photo.jpg","userId":"112096945625327662556"}}},"cell_type":"code","source":["net.train(X_train, y_train_one_hot, X_valid, y_valid_one_hot)"],"execution_count":232,"outputs":[{"output_type":"stream","text":["Epoch: 0, Step: 100 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.7602857028 \n","\n","Validation Set: Accuracy: 0.104017857143, Loss: 11.627183369 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 200 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.76327135093 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6295038484 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 300 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.72755441006 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6401425607 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 400 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.79134557913 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6445016136 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 500 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.85529423957 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6529845154 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 600 \n","\n","Training Set: Accuracy: 0.21875, Loss: 5.72235627451 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6680899872 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 700 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.78092373341 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6691853562 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 800 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.80494227658 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692804836 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 900 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.78568897545 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692972644 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 1000 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.85082855038 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692984167 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 1100 \n","\n","Training Set: Accuracy: 0.21875, Loss: 5.71354887391 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985253 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 1200 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.78396837211 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985301 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 1300 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.88561019273 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985325 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 0, Step: 1400 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.81488504305 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 100 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.80361576614 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 200 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.88015764382 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 300 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.82045769639 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 400 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.91886784692 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 500 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.76599198414 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 600 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.85969542173 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 700 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.76499604538 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 800 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.78802806514 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 900 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.82967698262 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 1000 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.83784400948 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 1100 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.81996943754 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 1200 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.81976269817 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 1300 \n","\n","Training Set: Accuracy: 0.28125, Loss: 5.7320057158 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 1, Step: 1400 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.82356130815 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 100 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.78918491377 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 200 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.82244616196 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 300 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.83822240051 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 400 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.73748979191 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 500 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.81542608352 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 600 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.74666507566 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 700 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.88342116957 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 800 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.66576970106 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 900 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.69329633035 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 1000 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.81434656026 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 1100 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.78023169472 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 1200 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.8258511033 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 1300 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.72025292364 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 2, Step: 1400 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.80694442837 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 100 \n","\n","Training Set: Accuracy: 0.0, Loss: 5.90598372349 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 200 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.87157900769 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 300 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.74025224998 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 400 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.79694184742 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 500 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.88425398626 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 600 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.71547671394 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 700 \n","\n","Training Set: Accuracy: 0.21875, Loss: 5.74537726611 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 800 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.75290640616 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 900 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.80448837607 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 1000 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.84814005313 \n","\n"],"name":"stdout"},{"output_type":"stream","text":["Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 1100 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.80030106125 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 1200 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.78719659112 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 1300 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.89028594666 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 3, Step: 1400 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.74490100107 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 100 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.7978159732 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 200 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.84493289184 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 300 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.84992582764 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 400 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.69665294399 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 500 \n","\n","Training Set: Accuracy: 0.21875, Loss: 5.74619178321 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 600 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.71309162267 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 700 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.8200473751 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 800 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.74983540792 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 900 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.85986513201 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 1000 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.83871031294 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 1100 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.82288180568 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 1200 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.73967417683 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 1300 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.86015524331 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 4, Step: 1400 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.72427499681 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 100 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.80984467263 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 200 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.81796771272 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 300 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.78971516956 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 400 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.93171321714 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 500 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.79831986812 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 600 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.793424894 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 700 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.76199137627 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 800 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.7788087719 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 900 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.83201233102 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 1000 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.8365245549 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 1100 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.7741967715 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 1200 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.70202262329 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 1300 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.83668106755 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 5, Step: 1400 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.83675010258 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 100 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.80650537502 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 200 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.77522614476 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 300 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.85784024044 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 400 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.82905832493 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 500 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.85887526288 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 600 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.87943881108 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 700 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.79103066876 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 800 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.776238858 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 900 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.78322728937 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 1000 \n","\n","Training Set: Accuracy: 0.0, Loss: 5.98118655265 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 1100 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.80688171425 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 1200 \n","\n","Training Set: Accuracy: 0.25, Loss: 5.71984130881 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 1300 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.78406782499 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 6, Step: 1400 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.74376305546 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 100 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.87154189927 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 200 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.77935217266 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 300 \n","\n","Training Set: Accuracy: 0.21875, Loss: 5.74358389781 \n","\n"],"name":"stdout"},{"output_type":"stream","text":["Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 400 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.86247794413 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 500 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.74541345917 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 600 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.88244962458 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 700 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.83403735918 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 800 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.87442333892 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 900 \n","\n","Training Set: Accuracy: 0.21875, Loss: 5.75325974218 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 1000 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.84850975064 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 1100 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.82548929281 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 1200 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.87786668977 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 1300 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.72980963228 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 7, Step: 1400 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.78551911905 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 100 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.7899767536 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 200 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.79340645061 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 300 \n","\n","Training Set: Accuracy: 0.21875, Loss: 5.72731701559 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 400 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.95361228901 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 500 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.82989222529 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 600 \n","\n","Training Set: Accuracy: 0.21875, Loss: 5.78071556304 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 700 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.73692974434 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 800 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.85521986628 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 900 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.79569201238 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 1000 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.77220716557 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 1100 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.87750375916 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 1200 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.89796313337 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 1300 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.8316949147 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 8, Step: 1400 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.77891813541 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 100 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.74226246004 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 200 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.83555869769 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 300 \n","\n","Training Set: Accuracy: 0.1875, Loss: 5.74791101454 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 400 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.78148080634 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 500 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.82854636451 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 600 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.86141958868 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 700 \n","\n","Training Set: Accuracy: 0.03125, Loss: 5.84580566167 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 800 \n","\n","Training Set: Accuracy: 0.09375, Loss: 5.84363017196 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 900 \n","\n","Training Set: Accuracy: 0.0625, Loss: 5.87364453073 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 1000 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.76575277559 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 1100 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.76199742316 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 1200 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.79815301318 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 1300 \n","\n","Training Set: Accuracy: 0.15625, Loss: 5.73835162197 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n","Epoch: 9, Step: 1400 \n","\n","Training Set: Accuracy: 0.125, Loss: 5.77175102547 \n","\n","Validation Set: Accuracy: 0.110803571429, Loss: 11.6692985326 \n","\n","Best Accuracy: 0.104017857143, Best Loss: 11.627183369 \n","\n","\n"],"name":"stdout"}]},{"metadata":{"id":"Kl8xpoCqf9G4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"oGa9dlu3k4Vg","colab_type":"text"},"cell_type":"markdown","source":["## Part 8: PyTorch Neural Network"]},{"metadata":{"id":"LecnVB1alWAa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":55}],"base_uri":"https://localhost:8080/","height":544},"outputId":"da6e6fc2-8083-4a8d-c681-e1a22bf2a31a","executionInfo":{"status":"ok","timestamp":1518974674931,"user_tz":300,"elapsed":27175,"user":{"displayName":"Logan Rooks","photoUrl":"//lh6.googleusercontent.com/-qETJT5Z1tdA/AAAAAAAAAAI/AAAAAAAAAVA/F5NHtBKc70Q/s50-c-k-no/photo.jpg","userId":"112096945625327662556"}}},"cell_type":"code","source":["!pip install http://download.pytorch.org/whl/cu80/torch-0.3.1-cp27-cp27mu-linux_x86_64.whl \n","!pip install torchvision \n","!pip install pillow==4.0.0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting torch==0.3.1 from http://download.pytorch.org/whl/cu80/torch-0.3.1-cp27-cp27mu-linux_x86_64.whl\n","  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.1-cp27-cp27mu-linux_x86_64.whl (496.9MB)\n","\u001b[K    100% || 496.9MB 67.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torch==0.3.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from torch==0.3.1)\n","Installing collected packages: torch\n","Successfully installed torch-0.3.1\n","Collecting torchvision\n","  Downloading torchvision-0.2.0-py2.py3-none-any.whl (48kB)\n","\u001b[K    100% || 51kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from torchvision)\n","Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torchvision)\n","Requirement already satisfied: torch in /usr/local/lib/python2.7/dist-packages (from torchvision)\n","Collecting pillow>=4.1.1 (from torchvision)\n","  Downloading Pillow-5.0.0-cp27-cp27mu-manylinux1_x86_64.whl (5.8MB)\n","\u001b[K    100% || 5.9MB 212kB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from torch->torchvision)\n","Installing collected packages: pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.0.0 torchvision-0.2.0\n","Collecting pillow==4.0.0\n","  Downloading Pillow-4.0.0-cp27-cp27mu-manylinux1_x86_64.whl (5.6MB)\n","\u001b[K    100% || 5.6MB 206kB/s \n","\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from pillow==4.0.0)\n","Installing collected packages: pillow\n","  Found existing installation: Pillow 5.0.0\n","    Uninstalling Pillow-5.0.0:\n","      Successfully uninstalled Pillow-5.0.0\n","Successfully installed pillow-4.0.0\n"],"name":"stdout"}]},{"metadata":{"id":"BIhBgNB7oY_r","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision.transforms as T\n","import torchvision.datasets as dsets\n","import torch.nn.parallel\n","import torch.utils.data\n","\n","# if gpu is to be used\n","use_cuda = torch.cuda.is_available()\n","FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n","LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n","ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n","Tensor = FloatTensor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b0oxTYGevHve","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def sigmoid(x):\n","  return 1 / (1 + np.exp(-x))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Oewhukdps7U2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class Swish(nn.Module):\n","  def __init__(self, beta=1.0):\n","    super(Swish, self).__init__()\n","    self.beta = beta\n","  \n","  def forward(self, x):\n","    return x * sigmoid(self.beta * x)\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"81K6NbaUpIDE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["n_inputs = 32*32\n","n_outputs = 6\n","n_hidden = 40\n","\n","model = torch.nn.Sequential(\n","        torch.nn.Linear(n_inputs, n_hidden),\n","        torch.nn.BatchNorm1d(n_hidden),\n","        torch.nn.ELU(),\n","        torch.nn.Linear(n_hidden, n_outputs)\n",")\n","if use_cuda:\n","  model.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MJgb240Up6AV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["loss_fn = torch.nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AET0ZbHFqvft","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["learning_rate = 1e-2\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XMCLPw_K4aD3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def data_label_split(dataset, label_map, one_hot_code=False, dtype=torch.FloatTensor):\n","    data = dataset[\"Data\"][dataset[\"Label\"].isin(label_map.keys())]\n","    labels = np.array([label_map.get(label) for label in dataset[\"Label\"][dataset[\"Label\"].isin(label_map.keys())]])\n","    n_out = labels.shape[1]\n","        \n","    flat_data = np.array(data.tolist())\n","    X = torch.FloatTensor(np.concatenate((np.ones((flat_data.shape[0], 1)), flat_data), axis=1)).type(dtype)\n","    y = torch.FloatTensor(np.array(labels).reshape(-1, n_out)).type(dtype)\n","    return X, y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TU8DfiSm4bnS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["actors = ['Lorraine Bracco', 'Peri Gilpin', 'Angie Harmon', 'Alec Baldwin', 'Bill Hader', 'Steve Carell']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7xf-COOt4ix5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["directory = \"/content/CSC411/Project 2/\"\n","# Reformatting dataset\n","sets = [\"train\", \"validation\", \"test\"]\n","dataset = {set_type: pd.DataFrame(columns=[\"Data\", \"Label\"]) for set_type in sets}\n","\n","n_samples = {\"train\": 120, \"validation\": 10, \"test\": 10, \"total\": 140}\n","# n_samples = {\"train\": 2, \"validation\": 10, \"test\": 10, \"total\": 140}\n","\n","np.random.seed(411)\n","for actor in actors:\n","    name = actor.split()[1].lower()\n","    # Create random permutation of indices to load images in random order\n","    indices = np.random.permutation(range(n_samples[\"total\"]))\n","    i = 0 # Required to keep track of current image No.\n","    for set_type in sets:\n","        set_actor_data = []\n","        for sample in range(n_samples[set_type]):\n","            filename = name + str(indices[i]) + '.jpg'\n","            img_data = imread(directory + \"cropped/\" + filename).flatten() / 255.0\n","            set_actor_data.append([img_data] + [name])\n","            i += 1\n","        set_actor_data = pd.DataFrame(set_actor_data, columns = list(dataset[set_type]))\n","        dataset[set_type] = pd.concat([dataset[set_type], set_actor_data], ignore_index=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cUQlrcva4lOy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train = dataset[\"train\"].sample(frac=1, random_state=411)\n","validation = dataset[\"validation\"].sample(frac=1, random_state=411)\n","test = dataset[\"test\"].sample(frac=1, random_state=411)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MlgBe5q65KWk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["label_map = {'bracco': [1, 0, 0, 0, 0, 0],\n","            'gilpin': [0, 1, 0, 0, 0, 0],\n","            'harmon': [0, 0, 1, 0, 0, 0],\n","            'baldwin': [0, 0, 0, 1, 0, 0],\n","            'hader': [0, 0, 0, 0, 1, 0],\n","            'carell': [0, 0, 0, 0, 0, 1]}   \n","X_train, y_train = data_label_split(train, label_map)\n","X_valid, y_valid = data_label_split(validation, label_map, dtype=Tensor)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v4xYLKfixAX7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_batches(X, y, batch_size, dtype=torch.FloatTensor):\n","  n_samples = X.shape[0]\n","  \n","  if n_samples % batch_size != 0:\n","    assert ValueError\n","    \n","  batch_indices = np.random.permutation(range(n_samples)).reshape(-1,batch_size)\n","  X_batches = torch.FloatTensor(X[batch_indices,:]).type(dtype)\n","  y_batches = torch.FloatTensor(y[batch_indices,:]).type(dtype)\n","  \n","  return X_batches, y_batches"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r3HwqhZuwyi2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":827},"outputId":"4696347d-c5ec-4894-bf66-0852f272bf6e","executionInfo":{"status":"error","timestamp":1518977744488,"user_tz":300,"elapsed":655,"user":{"displayName":"Logan Rooks","photoUrl":"//lh6.googleusercontent.com/-qETJT5Z1tdA/AAAAAAAAAAI/AAAAAAAAAVA/F5NHtBKc70Q/s50-c-k-no/photo.jpg","userId":"112096945625327662556"}}},"cell_type":"code","source":["batch_size = 16\n","n_samples = X_train.shape[0]\n","n_batches = int(n_samples / batch_size)\n","n_epochs = 300\n","\n","for epoch in range(n_epochs):\n","  X_batches, y_batches = get_batches(X_train, y_train, batch_size, dtype=Tensor)\n","  step = 0\n","  running_loss = 0.0\n","  for X_batch, y_batch in zip(X_batches, y_batches):\n","    y_pred = model(Variable(X_batch))\n","    loss = loss_fn(y_pred, y_batch)\n","    running_loss += loss\n","    model.zero_grad()  \n","    loss.backward()    \n","    optimizer.step()   \n","    step += 1\n","    if step % 200 == 0:\n","      avg_loss = running_loss / 200.0\n","      y_pred_valid = model(Variable(X_valid))\n","      valid_loss = loss_fn(y_pred_valid, y_valid)\n","      \n","      n_samples = X_valid.shape[0]\n","      n_correct = (y_pred_valid == y_valid).sum()\n","      valid_accuracy = n_correct / n_samples\n","      \n","      print(\"Epoch: {}, Step: {} \\nLoss: {}, Accuracy: {}, Validation Loss: {}, Validation Accuracy: {}\".format(epoch, step, avg_loss, validation_loss))\n","      \n","      "],"execution_count":51,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-51-9209b77377e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: size mismatch at /pytorch/torch/lib/THC/generic/THCTensorMathBlas.cu:247"]}]},{"metadata":{"id":"YaClYTCI87k8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}